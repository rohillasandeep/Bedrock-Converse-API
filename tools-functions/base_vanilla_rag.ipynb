{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f4db31",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "This notebook introduces how to build simple RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import boto3, json, textwrap\n",
    "import re\n",
    "from enum import Enum\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "# Create a session with AWS and initialize a Bedrock client for conversational AI models\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Models(Enum):\n",
    "    # Enum for storing model identifiers for different AI models.\n",
    "    # Each member represents a specific model hosted by various platforms like Anthropic and Meta.\n",
    "    \n",
    "    Sonnet = \"anthropic.claude-3-sonnet-20240229-v1:0\"  \n",
    "    Haiku = \"anthropic.claude-3-haiku-20240307-v1:0\"   \n",
    "    Llama = \"meta.llama3-8b-instruct-v1:0\"            \n",
    "    Cohere = \"cohere.command-r-plus-v1:0\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# List to hold the conversation's flow\n",
    "message_list = []\n",
    "\n",
    "# Starting message from the user to the model\n",
    "initial_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        { \"text\": \"How are you today?\" } \n",
    "    ],\n",
    "}\n",
    "\n",
    "# Append the initial message to the conversation list\n",
    "message_list.append(initial_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Using Bedrock SDK to send a message to the model and get a response\n",
    "response = bedrock.converse(\n",
    "    modelId=Models.Sonnet.value,\n",
    "    messages=message_list,  # Conversation history\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 3000,  # Maximum length of the model's response\n",
    "        \"temperature\": 0    # Sampling temperature, 0 for deterministic response\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Extract the message part of the response from the model\n",
    "response_message = response['output']['message']\n",
    "\n",
    "# Print the response message formatted as JSON for readability\n",
    "print(json.dumps(response_message, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(text):\n",
    "    response = bedrock.invoke_model(\n",
    "        body=json.dumps({\n",
    "            'inputText': text\n",
    "        }),\n",
    "        modelId=\"amazon.titan-embed-text-v1\",\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\",\n",
    "    )\n",
    "    #print(response)\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return response_body.get(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f301b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oss_connection():\n",
    "    host = 'erz3fznnf3antezuu2bc.us-west-2.aoss.amazonaws.com'\n",
    "    region = 'us-west-2'\n",
    "    service = 'aoss'\n",
    "    index = 'bedrock-knowledge-base-default-index'\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "    ospy_client = OpenSearch(\n",
    "        hosts = [{'host': host, 'port': 443}],\n",
    "        http_auth = auth,\n",
    "        use_ssl = True,\n",
    "        verify_certs = True,\n",
    "        connection_class = RequestsHttpConnection,\n",
    "        pool_maxsize = 20\n",
    "    )\n",
    "\n",
    "    return ospy_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What are the characteristics of bull dog breed?'\n",
    "vectors = get_vectors(question)\n",
    "k = 4 # number of neighbours, size and k are the same to return k results in total. If size is not specified, k results will be returned per shard.\n",
    "qry = {\n",
    "  \"size\": 3,\n",
    "  \"query\": {\n",
    "    \"knn\": {\n",
    "      \"bedrock-knowledge-base-default-vector\": {\n",
    "        \"vector\": vectors,\n",
    "        \"k\": 2\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "print(\"Query generated for OpenSearch\")\n",
    "print(json.dumps(qry, indent=4))\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95139761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oss_client = get_oss_connection()\n",
    "\n",
    "index = 'bedrock-knowledge-base-default-index'\n",
    "\n",
    "query = {\n",
    "    \"size\": 7,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "        \"bedrock-knowledge-base-default-vector\": {\n",
    "            \"vector\": vectors,\n",
    "            \"k\": 2\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "\n",
    "response = oss_client.search(\n",
    "        body = query,\n",
    "        index = index\n",
    "    )\n",
    "\n",
    "hits = response['hits']['hits']\n",
    "context = []\n",
    "for hit in hits:\n",
    "        #print(json.dumps(hit[\"_source\"][\"AMAZON_BEDROCK_TEXT_CHUNK\"], indent=4))\n",
    "    context.append(hit[\"_source\"][\"AMAZON_BEDROCK_METADATA\"])\n",
    "    context.append(hit[\"_source\"][\"AMAZON_BEDROCK_TEXT_CHUNK\"])\n",
    "\n",
    "print(\"Response from OpenSearch\")\n",
    "print(json.dumps(context, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49149da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are a friendly and honest chatbot agent.\n",
    "        Based on the contents of <doc/> XML tag, provide answer including document source for, question listed in <question/> XML tag. \n",
    "        Answer \"Error: I did not find a valid answer.\" if not present in the document. \n",
    "        <doc>{context}</doc>\n",
    "        <question>{question}</question>\"\"\"\n",
    "\n",
    "\n",
    "llm_prompt = prompt_template.format(context='\\n'.join(context),question=question)\n",
    "\n",
    "    # List to hold the conversation's flow\n",
    "message_list = []\n",
    "\n",
    "    # Starting message from the user to the model\n",
    "initial_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            { \"text\": llm_prompt } \n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Append the initial message to the conversation list\n",
    "message_list.append(initial_message)\n",
    "\n",
    "response = bedrock.converse(\n",
    "        modelId=Models.Sonnet.value,\n",
    "        messages=message_list,  # Conversation history\n",
    "        inferenceConfig={\n",
    "            \"maxTokens\": 2000,  # Maximum length of the model's response\n",
    "            \"temperature\": 0    # Sampling temperature, 0 for deterministic response\n",
    "        },\n",
    "    )\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
